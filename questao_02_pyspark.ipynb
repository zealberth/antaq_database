{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, to_timestamp, regexp_replace\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all(dfs):\n",
    "    \n",
    "    if len(dfs) == 0:\n",
    "        return None\n",
    "    \n",
    "    df = dfs[0]\n",
    "    \n",
    "    for df2 in dfs[1:]:\n",
    "        df = df.union(df2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao_2020 = spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "  .csv(\"data/raw/2020Atracacao.txt\")\n",
    "\n",
    "df_atracacao_2019 = spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "  .csv(\"data/raw/2019Atracacao.txt\")\n",
    "\n",
    "df_atracacao_2018 = spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "  .csv(\"data/raw/2018Atracacao.txt\")\n",
    "\n",
    "dfs = [df_atracacao_2020, df_atracacao_2019, df_atracacao_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = merge_all(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IDAtracacao', 'int'),\n",
       " ('CDTUP', 'string'),\n",
       " ('IDBerco', 'string'),\n",
       " ('Berço', 'string'),\n",
       " ('Porto Atracação', 'string'),\n",
       " ('Apelido Instalação Portuária', 'string'),\n",
       " ('Complexo Portuário', 'string'),\n",
       " ('Tipo da Autoridade Portuária', 'string'),\n",
       " ('Data Atracação', 'string'),\n",
       " ('Data Chegada', 'string'),\n",
       " ('Data Desatracação', 'string'),\n",
       " ('Data Início Operação', 'string'),\n",
       " ('Data Término Operação', 'string'),\n",
       " ('Ano', 'int'),\n",
       " ('Mes', 'string'),\n",
       " ('Tipo de Operação', 'string'),\n",
       " ('Tipo de Navegação da Atracação', 'string'),\n",
       " ('Nacionalidade do Armador', 'int'),\n",
       " ('FlagMCOperacaoAtracacao', 'int'),\n",
       " ('Terminal', 'string'),\n",
       " ('Município', 'string'),\n",
       " ('UF', 'string'),\n",
       " ('SGUF', 'string'),\n",
       " ('Região Geográfica', 'string'),\n",
       " ('Nº da Capitania', 'string'),\n",
       " ('Nº do IMO', 'int')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atracacao.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, to_timestamp(df[name], 'dd/MM/yyyy HH:mm:ss'))\n",
    "    return df \n",
    "\n",
    "# Assign all column names to `columns`\n",
    "columns = ['Data Atracação', 'Data Chegada','Data Desatracação', 'Data Início Operação', 'Data Término Operação']\n",
    "\n",
    "# Conver the `df` columns to `FloatType()`\n",
    "df_atracacao = convertColumn(df_atracacao, columns)\n",
    "                           \n",
    "# print(df_atracacao.dtypes)\n",
    "\n",
    "# df_atracacao.select('Data Chegada').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEsperaAtracacao: Atracação - Chegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEsperaAtracacao\", \n",
    "    (F.col(\"Data Atracação\").cast(\"long\") - F.col(\"Data Chegada\").cast(\"long\"))/60.\n",
    ")\n",
    "\n",
    "# cols = ['Data Atracação','Data Chegada','TEsperaAtracacao']\n",
    "# df_atracacao.select(*cols).show(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEsperaInicioOp:  Início - Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEsperaInicioOp\", \n",
    "    (F.col(\"Data Início Operação\").cast(\"long\") - F.col(\"Data Atracação\").cast(\"long\"))/60.\n",
    ")\n",
    "\n",
    "# cols = ['Data Início Operação','Data Atracação','TEsperaInicioOp']\n",
    "# df_atracacao.select(*cols).show(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOperacao: Término - Início"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TOperacao\", \n",
    "    (F.col(\"Data Término Operação\").cast(\"long\") - F.col(\"Data Início Operação\").cast(\"long\"))/60.\n",
    ")\n",
    "\n",
    "# cols = ['Data Término Operação','Data Início Operação','TOperacao']\n",
    "# df_atracacao.select(*cols).show(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEsperaDesatracacao: Desatracação - Término"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEsperaDesatracacao\", \n",
    "    (F.col(\"Data Desatracação\").cast(\"long\") - F.col(\"Data Término Operação\").cast(\"long\"))/60.\n",
    ")\n",
    "\n",
    "# cols = ['Data Desatracação','Data Término Operação','TEsperaDesatracacao']\n",
    "# df_atracacao.select(*cols).show(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAtracado: Desatracação - Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TAtracado\", \n",
    "    (F.col(\"Data Desatracação\").cast(\"long\") - F.col(\"Data Atracação\").cast(\"long\"))/60.\n",
    ")\n",
    "\n",
    "# cols = ['Data Desatracação','Data Atracação','TAtracado']\n",
    "# df_atracacao.select(*cols).show(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEstadia: Desatracação - Chegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEstadia\", \n",
    "    (F.col(\"Data Desatracação\").cast(\"long\") - F.col(\"Data Chegada\").cast(\"long\"))/60.\n",
    ")\n",
    "\n",
    "# cols = ['Data Desatracação','Data Chegada','TEstadia']\n",
    "# df_atracacao.select(*cols).show(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao.write.option(\"quoteAll\", True).csv(\"data/processed/atracacao_fato.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga_2020 = spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "  .csv(\"data/raw/2020Carga.txt\")\n",
    "\n",
    "df_carga_2019 = spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "  .csv(\"data/raw/2019Carga.txt\")\n",
    "\n",
    "df_carga_2018 = spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "  .csv(\"data/raw/2018Carga.txt\")\n",
    "\n",
    "dfs = [df_carga_2020, df_carga_2019, df_carga_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga = merge_all(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_carga = df_carga.join(df_atracacao, df_carga.IDAtracacao == df_atracacao.IDAtracacao).select(df_carga[\"*\"], df_atracacao[\"Ano\"], df_atracacao[\"Mes\"], df_atracacao[\"Porto Atracação\"], df_atracacao[\"SGUF\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peso líquido da carga (Carga não conteinerizada = Peso bruto e Carga conteinerizada = Peso sem contêiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "commaToDot = udf(lambda x : float(str(x).replace(',', '.')), FloatType())\n",
    "\n",
    "df_carga = df_carga.withColumn(\n",
    "    \"VLPesoCargaBruta\", \n",
    "    commaToDot('VLPesoCargaBruta')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga = df_carga.withColumn(\n",
    "    \"Peso líquido da carga\", \n",
    "    col(\"VLPesoCargaBruta\")\n",
    ")\n",
    "\n",
    "\n",
    "df_carga = df_carga.withColumn(\n",
    "    \"Peso líquido da carga\", \n",
    "    F.when( (col(\"FlagConteinerTamanho\") == '20')  & (col(\"FlagConteinerTamanho\").isNotNull()),\n",
    "           (col(\"VLPesoCargaBruta\") - 2.3)).otherwise(F.when( (col(\"FlagConteinerTamanho\") == '40'),\n",
    "           (col(\"VLPesoCargaBruta\") - 3.7)).otherwise(col(\"VLPesoCargaBruta\")))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga.write.option(\"quoteAll\", True).csv(\"data/processed/carga_fato.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
