{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, to_timestamp, regexp_replace\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all(dfs):\n",
    "    \n",
    "    if len(dfs) == 0:\n",
    "        return None\n",
    "    \n",
    "    df = dfs[0]\n",
    "    \n",
    "    for df2 in dfs[1:]:\n",
    "        df = df.union(df2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_raw = 'data/raw/'\n",
    "directory_processed = 'data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anos_interesse = ['2020', '2019', '2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for ano in anos_interesse:\n",
    "    dfs.append(spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "                          .csv(f\"{directory_raw}{ano}Atracacao.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = merge_all(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, to_timestamp(df[name], 'dd/MM/yyyy HH:mm:ss'))\n",
    "    return df \n",
    "\n",
    "columns = ['Data Atracação', 'Data Chegada','Data Desatracação', 'Data Início Operação', 'Data Término Operação']\n",
    "\n",
    "df_atracacao = convertColumn(df_atracacao, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEsperaAtracacao: Atracação - Chegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEsperaAtracacao\", \n",
    "    (F.col(\"Data Atracação\").cast(\"long\") - F.col(\"Data Chegada\").cast(\"long\"))/60.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEsperaInicioOp:  Início - Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEsperaInicioOp\", \n",
    "    (F.col(\"Data Início Operação\").cast(\"long\") - F.col(\"Data Atracação\").cast(\"long\"))/60.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOperacao: Término - Início"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TOperacao\", \n",
    "    (F.col(\"Data Término Operação\").cast(\"long\") - F.col(\"Data Início Operação\").cast(\"long\"))/60.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEsperaDesatracacao: Desatracação - Término"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEsperaDesatracacao\", \n",
    "    (F.col(\"Data Desatracação\").cast(\"long\") - F.col(\"Data Término Operação\").cast(\"long\"))/60.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAtracado: Desatracação - Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TAtracado\", \n",
    "    (F.col(\"Data Desatracação\").cast(\"long\") - F.col(\"Data Atracação\").cast(\"long\"))/60.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEstadia: Desatracação - Chegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atracacao = df_atracacao.withColumn(\n",
    "    \"TEstadia\", \n",
    "    (F.col(\"Data Desatracação\").cast(\"long\") - F.col(\"Data Chegada\").cast(\"long\"))/60.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar tabela final de Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory_processed):\n",
    "    os.makedirs(directory_processed)\n",
    "\n",
    "df_atracacao.write.mode(\"overwrite\").option(\"quoteAll\", True).csv(f\"{directory_processed}atracacao_fato.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for ano in anos_interesse:\n",
    "    dfs.append(spark.read.options(header='True', inferSchema='True', delimiter=';') \\\n",
    "                          .csv(f\"{directory_raw}{ano}Carga.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga = merge_all(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge entre as tabelas de Carga e Atracação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga = df_carga.join(df_atracacao, df_carga.IDAtracacao == df_atracacao.IDAtracacao) \\\n",
    "                    .select(df_carga[\"*\"], df_atracacao[\"Ano\"], df_atracacao[\"Mes\"], df_atracacao[\"Porto Atracação\"], df_atracacao[\"SGUF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peso líquido da carga (Carga não conteinerizada = Peso bruto e Carga conteinerizada = Peso sem contêiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "commaToDot = udf(lambda x : float(str(x).replace(',', '.')), FloatType())\n",
    "\n",
    "df_carga = df_carga.withColumn(\n",
    "    \"VLPesoCargaBruta\", \n",
    "    commaToDot('VLPesoCargaBruta')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carga = df_carga.withColumn(\n",
    "    \"Peso líquido da carga\", \n",
    "    col(\"VLPesoCargaBruta\")\n",
    ")\n",
    "\n",
    "\n",
    "df_carga = df_carga.withColumn(\n",
    "    \"Peso líquido da carga\", \n",
    "    F.when( (col(\"FlagConteinerTamanho\") == '20')  & (col(\"FlagConteinerTamanho\").isNotNull()),\n",
    "           (col(\"VLPesoCargaBruta\") - 2.3)).otherwise(F.when( (col(\"FlagConteinerTamanho\") == '40'),\n",
    "           (col(\"VLPesoCargaBruta\") - 3.7)).otherwise(col(\"VLPesoCargaBruta\")))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar tabela final de Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory_processed):\n",
    "    os.makedirs(directory_processed)\n",
    "\n",
    "df_carga.write.mode(\"overwrite\").option(\"quoteAll\", True).csv(f\"{directory_processed}carga_fato.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
